{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import openai\n",
    "import time\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./IMDB Dataset.csv')\n",
    "\n",
    "\n",
    "# Initialize a column for predicted sentiments\n",
    "df['predicted_sentiment'] = None\n",
    "\n",
    "# Process in batches of 20 reviews\n",
    "batch_size = 20\n",
    "total_reviews = len(df)\n",
    "\n",
    "for start in range(0, total_reviews, batch_size):\n",
    "    end = min(start + batch_size, total_reviews)\n",
    "    reviews = df['review'][start:end].tolist()\n",
    "\n",
    "    # Numbering each review in the batch\n",
    "    numbered_reviews = [f\"{i+1}. {review}\" for i, review in enumerate(reviews)]\n",
    "\n",
    "    while True:\n",
    "        # run code for only 1000 samples since its costly to run for 50,000 records\n",
    "        if end >1000:\n",
    "            break\n",
    "        try:\n",
    "            # Formatting the reviews into a string for the prompt\n",
    "            reviews_content = \"\\n\".join(numbered_reviews)\n",
    "\n",
    "            # Send the request to OpenAI\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Classify each of the following reviews as either 'positive' or 'negative'. Please return your classifications in the form of a list. For example, ['positive', 'negative', ...]\"},\n",
    "                    {\"role\": \"user\", \"content\": reviews_content},\n",
    "                    {\"role\": \"assistant\", \"content\": \"\"},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Convert the response to a list\n",
    "            predicted_sentiments = ast.literal_eval(response.choices[0].message.content)\n",
    "\n",
    "            # Check the number of predictions\n",
    "            if len(predicted_sentiments) == len(reviews):\n",
    "                df.loc[start:end-1, 'predicted_sentiment'] = predicted_sentiments\n",
    "                df.to_csv('./IMDB Dataset_with_Predictions.csv', index=False)\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Error: The number of predictions does not match the number of reviews for batch starting at index {start}.\")\n",
    "                break\n",
    "\n",
    "        except openai.error.RateLimitError:\n",
    "            print(\"Rate limit reached. Waiting for 45 seconds before retrying...\")\n",
    "            time.sleep(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b194b078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.00%\n",
      "Precision: 82.00%\n",
      "Confusion Matrix:\n",
      "[[20506  4494]\n",
      " [ 4506 20494]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "\n",
    "# Filter out rows where 'predicted_sentiment' is null or missing in case we decide to rerun code for small sample\n",
    "filtered_df = df.dropna(subset=['predicted_sentiment'])\n",
    "\n",
    "# Count the number of matches between predicted and actual sentiments in the filtered DataFrame\n",
    "correct_predictions = (filtered_df['predicted_sentiment'] == filtered_df['sentiment']).sum()\n",
    "total_predictions = len(filtered_df)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "# Calculate precision\n",
    "# Note: Precision is calculated for each class individually and then averaged\n",
    "precision = precision_score(filtered_df['sentiment'], filtered_df['predicted_sentiment'], average='weighted')\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(filtered_df['sentiment'], filtered_df['predicted_sentiment'])\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57505c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
